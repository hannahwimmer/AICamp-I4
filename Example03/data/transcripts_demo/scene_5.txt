OK, so we believe, as an industry, that in the next one year,
the vast majority of programmers will be replaced by AI
programmers.
We also believe that within one year, you
will have graduate-level mathematicians that
are at the tipi top of graduate math programs.
There's lots of reasons to think this is going to happen.
This is the consensus.
OK, well, that's pretty interesting.
Now, I can't do that kind of math.
Very few people can do that math.
How can the computer do that math better than anybody else?
To some degree, it's because math has a simpler
language than human language.
So the way these algorithms actually work
is they're doing essentially word prediction.
So you take a sentence.
You take a word out.
And then it learns how to put the correct word back in.
This is called the loss function.
And it's optimized to do that at a scale
to unimaginable to us as humans.
So you do the same thing for math.
But there you use a conjecture and then a proof format
through a protocol called lean.
In programming, it's pretty simple.
You just keep writing code until you pass the programming
test.
So strangely, the first question I was asked programmers
is what language do you program in the correct answer
as it doesn't matter?
Because you're trying to design for an outcome,
you don't care what code is generated by the computer.
This is a whole new world.
So that's one year.
What happens in two years?
Well, I've just told you about reasoning,
and I've told you about programming,
and I told you about math.
Programming plus math are the basis of sort
of our whole digital world.
So the evidence and the claims from the research groups
in OpenAI and Anthropocon so forth
is that there are now somewhere around 10% or 20%
of the code that they're developing in their research
programs is being generated by the computer.
That's called recursive self-improvement,
is the technical term.
So what happens when this thing starts to scale?
Well, a lot.
One way to say this is that within three to five years,
we'll have what is called general intelligence, HGI,
which can be defined as a system that is as smart
as the smartest mathematician, physicist,
our artist, writer, thinker, politician, maybe not
in the same level, but you get the idea.
Just the creative industries and so forth,
but imagine that in one computer.
Well, that's pretty interesting.
I call this by the way the San Francisco consensus
because everyone who believes this is in San Francisco.
It may be the water.
What happens when every single one of us has the equivalent
of the smartest human on every problem in our pocket?
To it means you have to best architect
when you have an architecture problem.
Now, the other thing that's going on
is the development of agente solutions.
And agents are referred to systems
that have input and output in memory.
And they learn.
An example here is that I want to buy another house.
I happen to like Virginia, I grew up in Virginia.
I say, find me a house in the greater McLean area.
Look at the, that's one agent.
Look at all the rules, figure out how big a house I can build.
That's another agent.
Do the transaction to buy the land.
That's another agent.
Design the house with a human architect.
But sort of ignore them for most of the thing
that they have to sign it off.
And then I approve it and then find the contractor, right?
Higher the contractor, pay the bills.
And at the end, sue the contractor for lack of performance.
OK?
Now, I just gave you the stupidest possible explanation.
I just described every business process, every government
process, and every sort of academic process in our nation.
So it isn't just the program.
It's just going to be out of work.
We're all going to be out of work.
No, it's not a consequence.
I'll come to that.
But the reason I want to make the point here is that in the next year
or two, this foundation is being locked in.
And it's not going to stop it.
It gets much more interesting after that.
Because remember, the computers are now doing self-improvement.
They're learning how to plan, and they
don't have to listen to us anymore.
We call that superintelligence or ASI, artificial superintelligence.
And this is the theory that there will be computers that are smarter
than the sum of humans.
The San Francisco convinces this occurs within six years,
just based on scaling.
Now, in order to pull this off, you have
to have an enormous amount of power.
I was here yesterday, testifying about this.
And we need, I can talk at some length about how many gigawatts,
and how many nuclear power plants, and all
they've got to think of if we can talk about it separately.
This path is not understood in our society.
There's no language for what happens with the arrival of this.
I wrote a book on this with Henry Kissinger called Genesis,
which I recommend, obviously.
Because I wrote an available, available in your usual places.
But the important point is, this is happening faster
than our human, that our society, our democracy, our laws,
will address, and there's lots of implications.
That's why it's underhyped.
People do not understand what happens when you have intelligence
at this level, which is largely free.
That's the point.
How do we get ready for it?
Well, we start by talking about it.
And by the way, on the jobs thing, everyone assumes
that automation will eliminate jobs.
If you look at the history of automation,
ever since the looms, and in 300 years ago,
the jobs are changed, but more jobs are created than destroyed.
In this case, you'd have to convince me
that this time is different.
If you look in Asia, for whatever reason
are choosing not to have children,
their Asian reproduction rate is in the order of 1.0 or lower.
So they're rapidly disappearing.
So the Asian countries are very, very quickly automating.
The tools that I'm describing will allow
the few humans that will be working very hard
in 30 or 40 years if these trends continue.
The rest of us will be dependent on those hard-working humans.
It'll make their productivity more much greater.